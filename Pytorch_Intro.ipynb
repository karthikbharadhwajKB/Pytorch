{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d61d1356-c799-4c1d-beba-9beb130499f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffee8531-a0d9-451f-8ce9-6ebb2fa8a738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0+cu121'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "449a0e81-9d37-4c43-8d8c-bcd19ae7a5c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world!\n"
     ]
    }
   ],
   "source": [
    "print('hello world!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f43d1fa8-1066-4311-804a-20a77e950683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Oct 28 21:08:54 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 529.08       Driver Version: 529.08       CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA T1200 La... WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   43C    P8     3W /  40W |     94MiB /  4096MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     24636    C+G   ...ser\\Application\\brave.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c03053dd-da9b-4684-8cf2-0e07313e7dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69245f73-5c16-461b-93e8-d016bde35ebc",
   "metadata": {},
   "source": [
    "## PyTorch Fundamentals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f3bf8675-7a78-40c5-960f-00a67f1a5270",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "140a3965-4117-4ec6-b00e-8fec7a9c7ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0+cu121\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3809f34e-7647-4e5b-8725-a6b6a29d5244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\karthik.kolluri\\appdata\\local\\anaconda3\\envs\\torch_exps\\lib\\site-packages (3.8.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\karthik.kolluri\\appdata\\local\\anaconda3\\envs\\torch_exps\\lib\\site-packages (from matplotlib) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\karthik.kolluri\\appdata\\local\\anaconda3\\envs\\torch_exps\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\karthik.kolluri\\appdata\\local\\anaconda3\\envs\\torch_exps\\lib\\site-packages (from matplotlib) (4.43.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\karthik.kolluri\\appdata\\local\\anaconda3\\envs\\torch_exps\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in c:\\users\\karthik.kolluri\\appdata\\local\\anaconda3\\envs\\torch_exps\\lib\\site-packages (from matplotlib) (1.26.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\karthik.kolluri\\appdata\\local\\anaconda3\\envs\\torch_exps\\lib\\site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\karthik.kolluri\\appdata\\local\\anaconda3\\envs\\torch_exps\\lib\\site-packages (from matplotlib) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\karthik.kolluri\\appdata\\local\\anaconda3\\envs\\torch_exps\\lib\\site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\karthik.kolluri\\appdata\\local\\anaconda3\\envs\\torch_exps\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\karthik.kolluri\\appdata\\local\\anaconda3\\envs\\torch_exps\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2450f33a-5145-4a88-91df-02bd25246253",
   "metadata": {},
   "source": [
    "## 1. Introduction to Tensors. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5352159-dba8-4c27-9ba1-674aa99681f0",
   "metadata": {},
   "source": [
    "### creating tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0511eb9a-ae76-4a9f-89c7-cfd93009f76e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scalar \n",
    "scalar = torch.tensor(5)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47e8078e-f945-42b3-a8a2-98085823dccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88681797-8302-4132-bbe1-470804cc0c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting tensor back as python int \n",
    "scalar.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f245595-e12b-426c-a942-2582f0d431f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 5])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vector \n",
    "vector = torch.tensor([5,5])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4075774e-303f-48e1-8af3-2fb90cc9fa43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc5a3c1b-5c72-4fbd-a8ae-4829fa83faf7",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "a Tensor with 2 elements cannot be converted to Scalar",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mvector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: a Tensor with 2 elements cannot be converted to Scalar"
     ]
    }
   ],
   "source": [
    "vector.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0a2d659-84c5-42fd-b292-5637cb408e10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector[0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab5a3dac-4a52-44cc-b356-512a274bc672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "55ea1506-de57-4902-8b06-117f06e4547a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec7677a-dfa1-4bd1-94d8-dc7d4994a07e",
   "metadata": {},
   "source": [
    "### Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "41efdb7d-f326-4248-8c1d-467d465b8003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4, 8],\n",
       "        [2, 3]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Matrix = torch.tensor([[4,8],\n",
    "                      [2,3]])\n",
    "Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e6ce2392-8625-4560-ad3d-5e6b0e2254ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Matrix.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "64ea2ea8-9b32-4226-ac34-2cdc28374053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bb1fc1f2-936d-4901-8b5e-ce7cdb70c693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 8])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Slicing on Matrix\n",
    "Matrix[0] #first row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e9004614-7ac6-4003-a35b-dea313b11a20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 3])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Matrix[1] #second row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d9a773ef-5cd9-4c4d-8ea0-e214b262ec3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Matrix[0][1] #first row, 2nd column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17307198-dc19-4b8d-8caf-c7a1e539f09d",
   "metadata": {},
   "source": [
    "### Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "59c5906e-33a9-42a1-8fe4-03b88319835d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2, 3, 4],\n",
       "         [5, 6, 7],\n",
       "         [0, 1, 2]]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tensor = torch.tensor([[[2,3,4],\n",
    "                      [5,6,7],\n",
    "                      [0,1,2]]])\n",
    "\n",
    "Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1b1b087c-ba23-47c7-8cdd-0f2e4abbd9f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5af323f9-701f-4a93-aaa1-6d697d81a4b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7927008c-3554-41e1-9226-d69ec3bbe0b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 3, 4],\n",
       "        [5, 6, 7],\n",
       "        [0, 1, 2]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Slicing \n",
    "Tensor[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "409311a9-04d1-43a8-9422-4e8204dbaa38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2],\n",
       "         [3, 4]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#some examples\n",
    "A = torch.tensor([[[1,2],\n",
    "                  [3,4]]])\n",
    "\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00116ed3-5918-4d79-abd2-f3614dd5b825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 2])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060a53bf-6e0e-493c-9e69-fc1a7173e4fb",
   "metadata": {},
   "source": [
    "### Random Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "293c1073-e782-4fa8-a199-8898285ec909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0630, 0.7859, 0.1351, 0.2005],\n",
       "        [0.0024, 0.1872, 0.2681, 0.8307],\n",
       "        [0.7283, 0.3656, 0.9367, 0.6102]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor = torch.rand(3,4)\n",
    "\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76b6ec48-e461-4e4c-b2dc-3fd74534fcb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0d75e36-d3ec-44e8-97af-10416db37e42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4798, 0.3168, 0.1688, 0.4038],\n",
       "         [0.1909, 0.5011, 0.1945, 0.7437],\n",
       "         [0.9637, 0.5985, 0.3880, 0.0505]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor = torch.rand(1,3,4)\n",
    "\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92116e73-dd2c-4564-9549-48796dfe08ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af624f54-b787-43f4-b6d4-14f365951227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 244, 244]), 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a random tensor with similar shape of an image!\n",
    "random_tensor_image = torch.rand(size=(3,244,244)) #Depth, Height, Width. \n",
    "random_tensor_image.shape, random_tensor_image.ndim "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d511d9-7632-44d8-9396-de977dad8a40",
   "metadata": {},
   "source": [
    "### Zero, One Tensors \n",
    "\n",
    "example: Mask "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d9ed088-1fd3-4d33-b3c0-57ce4f9f1288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a tensor with all zeros\n",
    "zeros = torch.zeros(size=(3,4))\n",
    "\n",
    "zeros\n",
    "\n",
    "zeros.ndim\n",
    "\n",
    "zeros.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "edaaba8f-b184-4186-a71d-b22826cff879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 6])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a tensor with all ones\n",
    "ones = torch.ones(size=(3,6))\n",
    "\n",
    "ones\n",
    "\n",
    "ones.ndim\n",
    "\n",
    "ones.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea0866c5-6afa-4abd-a884-5eb2133b5922",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#datatypes\n",
    "ones.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6ac63d3-7fd4-4fff-8090-f2f848670411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating a zero tensor of size (3,3,3)\n",
    "\n",
    "zeros = torch.zeros(size=(3,3,3))\n",
    "\n",
    "zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b46bdbca-4171-4940-ada5-b6c123aa2f99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c58413f9-2717-4b48-98ab-05be79f1b198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa045d5a-b2f7-410b-9025-6bfc120f7d11",
   "metadata": {},
   "source": [
    "### Creating a tensors using range and like "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34c39bd0-11ed-4043-bc14-9042ce461b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\karthik.kolluri\\AppData\\Local\\Temp\\ipykernel_1008\\497691777.py:1: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "  torch.range(0,10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.range(0,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82523e38-4446-4800-8e67-82e69eb6f064",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.range() is deprecated! \n",
    "# so we should use torch.arange()!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0899f152-1363-419a-8121-790b22cf6c17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_to_ten = torch.arange(1,11)\n",
    "\n",
    "one_to_ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebde53c6-0448-4706-92ac-e919c0f3a24a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0,  88, 176, 264, 352, 440, 528, 616, 704, 792, 880, 968])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step = torch.arange(start=0, end=1000, step=88)\n",
    "\n",
    "step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e48a0df6-d691-4784-b612-5726dc2f3b29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step = torch.arange(start=1, end=11, step=1)\n",
    "\n",
    "step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918a16dd-9917-4df5-867d-f1ae312fee26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reverse ordering\n",
    "step = torch.arange(start=10, end=1, step=-1)\n",
    "\n",
    "step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "37cfedff-c475-4180-972b-1f8143244196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating Tensor using like!\n",
    "one_to_ten.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "27035d44-41c0-4354-ae8d-6629c94fbb58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I want to create a 10 zeros tensor (Vector)\n",
    "ten_zeros = torch.zeros_like(input=one_to_ten)\n",
    "\n",
    "ten_zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e15f2337-e117-4ae6-a34f-e9b84947ee3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ten_ones = torch.ones_like(input=one_to_ten)\n",
    "\n",
    "ten_ones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bb33b2-6a40-4639-9f3e-ccb1f0bc6bca",
   "metadata": {},
   "source": [
    "### Tensor Datatypes\n",
    "\n",
    "**Note:** Tensor Datatypes is one of the 3 big errors you'll run into with PyTorch and Deep Learning. \n",
    "\n",
    "1. Tensors not in right datatype.\n",
    "2. Tensors not in right Shape.\n",
    "3. Tensors not in right device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "732bc65a-a90f-4f3f-91fb-81d2d18e8705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Float_32\n",
    "\n",
    "float_32_tensor = torch.tensor([3.0, 6.0, 9.0], dtype=None)\n",
    "\n",
    "float_32_tensor\n",
    "\n",
    "float_32_tensor.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba627e7f-8083-4e6b-82d0-849ebffad863",
   "metadata": {},
   "source": [
    "Even we specify dtype as None but it's datatype is float_32\n",
    "\n",
    "Because In pytorch, default datatype is 'Float_32'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "90135404-cba6-4eba-a0c9-d7f7370c4f34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.], dtype=torch.float16)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.float16"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can change Float_32(default) to float_16 (anything!) \n",
    "\n",
    "float_16_tensor = torch.tensor([3.0, 6.0, 9.0], dtype=torch.float16) #torch.int\n",
    "\n",
    "float_16_tensor\n",
    "\n",
    "float_16_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "15d99586-33e7-4460-bcc5-1dba3d46d7f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 6, 9], dtype=torch.int32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.int32"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can change Float_32(default) to Int_32 (anything!) \n",
    "# Integers\n",
    "float_int_tensor = torch.tensor([3.0, 6.0, 9.0], dtype=torch.int32) #torch.int\n",
    "\n",
    "float_int_tensor\n",
    "\n",
    "float_int_tensor.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb434e5-9d7e-4c3a-bdd4-7c4c11ce4954",
   "metadata": {},
   "source": [
    "When we are creating tensor, we should remember of these three attributes: dtype, device, requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca4d9ab-9ab3-43da-92ec-406bcb831594",
   "metadata": {},
   "outputs": [],
   "source": [
    "float_16_tensor = torch.tensor([3.0, 6.0, 9.0], \n",
    "                               dtype=None, #What data type is the tensor (e.g: float_32, float_16)\n",
    "                               device=None, # What Device your tensor is on. \n",
    "                               # Device-on which device you are running the operation, default-> cpu (cpu or cuda)\n",
    "                               requires_grad=None) # Whether or not to track the gradients with this tensor operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7b3c32-3862-4754-bb42-9cc2adf0c691",
   "metadata": {},
   "source": [
    "## Precision in Computing!\n",
    "\n",
    "### In computer science, the precision of a numerical quantity is a measure of the detail in which the quantity is expressed. This is usually measured in bits, but sometimes in decimal digits. It is related to precision in mathematics, which describes the number of digits that are used to express a value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53548a16-c9fd-4619-a595-66efe36b2a2c",
   "metadata": {},
   "source": [
    "### Converting datatypes of Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8b3d5763-382c-4278-9f85-7513d9fcf143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_int_tensor = torch.tensor([1,2,3,5])\n",
    "\n",
    "float_int_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "03fb64cf-5d67-4f39-a19f-c176aa00cabd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float16"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#converting int tensor to float_16\n",
    "\n",
    "float_16_tensor = float_int_tensor.type(torch.float16)\n",
    "\n",
    "float_16_tensor.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc78f5a-bd4c-4401-b06e-4c9e7c0d1faf",
   "metadata": {},
   "source": [
    "## Getting Information from Tensors (Tensor Attributes)\n",
    "\n",
    "1. Tensors not right Datatype - To do get datatype from a tensor, can use `tensor.dtype`\n",
    "2. Tensors not right Shape - To do get Shape of a tensor, can use `tensor.shape`\n",
    "3. Tensors not right Device - To do get info about on which Device, can use `tensor.device` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "68be46e6-f51b-4791-8458-aae055a12cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensor.shape and tensor.size() will output same info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "242a0dfa-fd2e-4063-90d3-7f1eab2d957d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0352, 0.8944, 0.6499, 0.9203],\n",
       "        [0.7539, 0.6617, 0.9966, 0.9390],\n",
       "        [0.7422, 0.9957, 0.1653, 0.5026]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_tensor = torch.rand((3,4))\n",
    "\n",
    "some_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "88cd8d43-6ee3-4c5c-a72f-5b136dd5f0e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function Tensor.size>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Size is not a attribute,it's a function \n",
    "some_tensor.size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "40428ee1-6ac9-4188-b65d-196b5493a660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_tensor.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ef3cd870-d381-4589-ade7-548895330795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2a2c8062-8473-4f98-bf7c-9319fe0060c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0352, 0.8944, 0.6499, 0.9203],\n",
       "        [0.7539, 0.6617, 0.9966, 0.9390],\n",
       "        [0.7422, 0.9957, 0.1653, 0.5026]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datatype of the tensor: torch.float32\n",
      "Shape of the Tensor: torch.Size([3, 4])\n",
      "Device tensor is on: cpu\n"
     ]
    }
   ],
   "source": [
    "#Find out details about some tensor\n",
    "some_tensor\n",
    "\n",
    "print(f'Datatype of the tensor: {some_tensor.dtype}')\n",
    "\n",
    "print(f'Shape of the Tensor: {some_tensor.shape}')\n",
    "\n",
    "print(f'Device tensor is on: {some_tensor.device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0265054-bf96-46fe-a3a2-87fbf382ab4d",
   "metadata": {},
   "source": [
    "## Manipulating a tensor (Tensor Operations)\n",
    "\n",
    "Tensor Operations include: \n",
    "\n",
    "1) Additions\n",
    "2) Substractions\n",
    "3) Multiplications (element-wise)\n",
    "4) Division\n",
    "5) Matrix Mutliplication\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "951c23d7-5881-4ba6-91b5-5139c2191964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Addition \n",
    "A = torch.tensor([1,2,3])\n",
    "\n",
    "A\n",
    "\n",
    "scalar = 10 \n",
    "\n",
    "A = A + scalar \n",
    "\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "378a5074-97cb-45ad-afc2-64b76cc1a9f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Multiply tensor by 10 \n",
    "A = torch.tensor([1,2,3])\n",
    "\n",
    "A\n",
    "\n",
    "A * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7ba53353-8e98-4004-8b46-6a3773e63bd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9, -8, -7])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# substract 10 \n",
    "\n",
    "A - 10 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218d9bd4-750a-4cbe-8961-3385b6194976",
   "metadata": {},
   "source": [
    "PyTorch also has built-in funtions (add, sub, mut, div)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9ec70d0d-b0ab-43b5-b565-28bf7e6cf426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#multiply by 10 \n",
    "torch.mul(A,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "21e5a3e9-2861-4528-b8aa-da83662e7605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#add by 10 \n",
    "torch.add(A,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf5a3a0-9a31-4641-bba6-07eb18a16bbc",
   "metadata": {},
   "source": [
    "## Matrix Mutiplication \n",
    "\n",
    "Two main ways of performing multiplication in Neural Network and Deep learning. \n",
    "\n",
    "1. Element-wise multiplication (Scalar mutliplication)\n",
    "2. Matrix multiplication (Dot product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4f612386-859d-4f8c-8d38-8f60235ff0c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 8, 16, 24, 32])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Element-wise multiplication \n",
    "\n",
    "tensor = torch.tensor([1,2,3,4])\n",
    "\n",
    "scalar = torch.tensor(8)\n",
    "\n",
    "tensor * scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "daa30869-61b5-403f-bc1b-e77a879381f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  4,  9, 16])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Element-wise multiplication \n",
    "\n",
    "tensor = torch.tensor([1,2,3,4]) \n",
    "\n",
    "tensor * tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b22aa65d-ecee-4044-ab63-f5d88b8a496e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(30)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Matrix Mutliplication \n",
    "tensor = torch.tensor([1,2,3,4]) \n",
    "torch.matmul(tensor,tensor)\n",
    "\n",
    "#Analysis\n",
    "# tensor = [1,2,3,4]-T (Transpose) Shape -> 4x1 \n",
    "# tensor = [1,2,3,4] shape -> 1x4\n",
    "# matmul = tensor-T * tensor  shape -> (1x4) * (4x1) => 1 (scalar)\n",
    "# 1*1 + 2*2 + 3*3 + 4*4 => 1 + 4 + 9 + 16 => 30 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0eb2bd0a-0486-4281-a3b8-4a1a2484f7e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1*1 + 2*2 + 3*3 + 4*4 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d0bf90-9dbb-40ef-9fa9-2318cd4287a4",
   "metadata": {},
   "source": [
    "We can also do this same operation with for loop!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b316d031-cac3-4c5b-a610-aa63828a1fd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100000])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.arange(0,100000)\n",
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e15c8de4-caad-424c-87e5-ee1f033516b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(333328333350000)\n",
      "CPU times: total: 1.05 s\n",
      "Wall time: 1.52 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#for loop version (Matrix Multiplication)\n",
    "sum = 0\n",
    "for i in tensor:\n",
    "    sum += i*i\n",
    "print(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b3866d6f-3b80-435e-bbcc-cb7996bf5ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(333328333350000)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "torch.matmul(tensor,tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e19666d7-a9ff-412a-9e08-5fb9f6c8afd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Torch.matmul is optimized operation to do matrix multiplication!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28c3c27c-03ff-4669-bc03-0d770aa3ee4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 928 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(333328333350000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#Matrix Mutliplication (@) \n",
    "# @ -> signifies as matrix multiplication operator!\n",
    "tensor = torch.arange(0,100000)\n",
    "\n",
    "#dot product (tensor . tensor)\n",
    "tensor @ tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3561ebd-9e26-49b8-8aa0-076a64b018df",
   "metadata": {},
   "source": [
    "## Matrix Multiplication Rules\n",
    "There are two main rules that performing matrix multiplication needs to satisfy!!\n",
    "\n",
    "1. The **inner dimensions** must match: \n",
    "* `(3,2) @ (3,2)` -> won't work!\n",
    "* `(3,2) @ (2,3)` -> will work! \n",
    "* `(2,3) @ (3,2)` -> will work!\n",
    "\n",
    "2. The resulting matrix has the shape of the **outer dimension**\n",
    "* `(3,2) @ (2,3) -> (3,3)`\n",
    "* `(2,3) @ (3,2) -> (2,2)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9fd1945-fe01-4023-9bee-4caaf4a0f40a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 2]), torch.Size([3, 2]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m B \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m      6\u001b[0m A\u001b[38;5;241m.\u001b[39mshape, B\u001b[38;5;241m.\u001b[39mshape \n\u001b[1;32m----> 8\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43mB\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)"
     ]
    }
   ],
   "source": [
    "#Example (Inner dimension won't match)\n",
    "A = torch.rand(3,2)\n",
    "\n",
    "B = torch.rand(3,2)\n",
    "\n",
    "A.shape, B.shape \n",
    "\n",
    "torch.matmul(A,B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b8d1d8e-84e3-4b84-9936-8cca017ce8ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mA\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mB\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)"
     ]
    }
   ],
   "source": [
    "A @ B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08c68f37-067f-449e-8229-8752580797d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 2]), torch.Size([2, 3]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0878, 0.0870, 0.1772],\n",
       "        [0.2513, 0.2257, 0.4867],\n",
       "        [0.4424, 0.3825, 0.8440]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example (where Inner dimension are matching!)\n",
    "A = torch.rand(3,2)\n",
    "\n",
    "B = torch.rand(2,3)\n",
    "\n",
    "A.shape, B.shape \n",
    "\n",
    "torch.matmul(A,B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92ee1a28-4dc8-4828-840e-18d1fe614136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example of Outer dimension \n",
    "out = torch.matmul(torch.rand(3,2), torch.rand(2,3)) \n",
    "out.shape #(3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b2ec697-f621-4f10-9451-80aefe555146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = torch.matmul(torch.rand(3,10), torch.rand(10,3)) \n",
    "out.shape #(3,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e99ce1-25a8-409b-b822-6ba5ede95bbf",
   "metadata": {},
   "source": [
    "## One of the most common errors in deep learning: Shape Errors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "39393e74-bc5c-42a2-87d9-ec35e8746eb5",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 12\u001b[0m\n\u001b[0;32m      6\u001b[0m tensor_B \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m10\u001b[39m],\n\u001b[0;32m      7\u001b[0m                         [\u001b[38;5;241m9\u001b[39m,\u001b[38;5;241m11\u001b[39m],\n\u001b[0;32m      8\u001b[0m                         [\u001b[38;5;241m7\u001b[39m,\u001b[38;5;241m12\u001b[39m]])\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m#torch.mm(tensor_A,tensor_B) torch.mm() is same as torch.matmul() it's an alias for matmul()\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_A\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtensor_B\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)"
     ]
    }
   ],
   "source": [
    "#tensors for Matrix Multiplication \n",
    "tensor_A = torch.tensor([[1,2],\n",
    "                        [3,4],\n",
    "                        [5,6]])\n",
    "\n",
    "tensor_B = torch.tensor([[8,10],\n",
    "                        [9,11],\n",
    "                        [7,12]])\n",
    "\n",
    "\n",
    "#torch.mm(tensor_A,tensor_B) torch.mm() is same as torch.matmul() it's an alias for matmul()\n",
    "torch.matmul(tensor_A,tensor_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "47fa4508-afcf-4661-8922-63ca41e61eb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 2]), torch.Size([3, 2]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_A.shape, tensor_B.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd991abc-9d07-4ecc-b21b-d2c7321fa31c",
   "metadata": {},
   "source": [
    "#we can use Transpose to fix shape!\n",
    "\n",
    "A **Transpose** switches axis or dimensions of a given tensor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4792ff32-b7dd-4b68-a6c5-cac7f49c257c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 8, 10],\n",
       "        [ 9, 11],\n",
       "        [ 7, 12]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_B\n",
    "\n",
    "tensor_B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "238a8c6b-365f-47f6-b125-b65a150b0f50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 8,  9,  7],\n",
       "        [10, 11, 12]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_B_new = tensor_B.T\n",
    "\n",
    "tensor_B_new\n",
    "\n",
    "tensor_B_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7f0db276-9d62-41b4-869b-c13ebb5ee4bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 28,  31,  31],\n",
       "        [ 64,  71,  69],\n",
       "        [100, 111, 107]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Matrix Mutliplication \n",
    "tensor_result = torch.matmul(tensor_A, tensor_B.T)\n",
    "\n",
    "tensor_result\n",
    "\n",
    "tensor_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7eed94e-9206-4741-934e-ed531577a71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orginal shape of Tensor A : torch.Size([3, 2])\n",
      "Orginal shape of Tensor B : torch.Size([3, 2])\n",
      "Transposed shape of tensor B: torch.Size([2, 3])\n",
      "Matrix Mutliplication: torch.Size([3, 2]) @ torch.Size([2, 3]) --> inner dimension must match!\n",
      "Output shape: torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "#The Matrix Mutliplication operation works when tensor B is transposed!\n",
    "tensor_A = torch.rand((3,2))\n",
    "tensor_B = torch.rand((3,2))\n",
    "\n",
    "print(f'Orginal shape of Tensor A : {tensor_A.shape}')\n",
    "print(f'Orginal shape of Tensor B : {tensor_B.shape}')\n",
    "\n",
    "#we cannot perform matmul with these tensors\n",
    "#torch.matmul(tensor_A, tensor_B)\n",
    "\n",
    "#we need to perform transpose operation to solve this issue!\n",
    "tensor_B = tensor_B.T\n",
    "\n",
    "print(f'Transposed shape of tensor B: {tensor_B.shape}')\n",
    "\n",
    "print(f'Matrix Mutliplication: {tensor_A.shape} @ {tensor_B.shape} --> inner dimension must match!')\n",
    "\n",
    "output = torch.mm(tensor_A, tensor_B)\n",
    "\n",
    "print(f'Output shape: {output.shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52eaf70f-addb-4090-ae22-c7a6d3f61649",
   "metadata": {},
   "source": [
    "## Tensor Aggregation\n",
    "\n",
    "Finding Min, Max, Mean, Sum etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d804c4e6-92cd-4593-80fc-6c646f3cecdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([23, 25, 99,  7, 31, 83, 81, 83, 43, 42, 73, 76, 99, 33, 43,  6, 97, 55,\n",
       "        47, 71, 58, 98, 51, 46, 83, 25, 17, 17, 99, 52, 93, 69, 42, 32, 72, 74,\n",
       "        83, 42, 81, 25, 34, 51, 42, 48,  4, 55, 12, 56, 82, 17, 83, 61, 15, 22,\n",
       "        47, 12, 96, 61, 80, 42,  3, 47, 99, 44, 52, 55, 19, 42, 89, 11, 24, 81,\n",
       "         3, 26, 82, 18, 98,  6, 10, 17, 62, 40, 11, 56, 39, 70, 45, 97, 75, 10,\n",
       "        89, 26, 18,  9, 37, 55,  9, 42, 11, 56])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a tensor \n",
    "#random integers low=0, high=100,size = (100,) elements\n",
    "tensor = torch.randint(0,100,(100,))\n",
    "\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "56500720-85eb-435d-932f-dc3deb1ef45b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#finding min, max, mean, median, sum\n",
    "tensor.min()\n",
    "\n",
    "#same operation\n",
    "torch.min(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0738a510-3aa1-4e1d-b892-35922eeb4ac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(99)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "21ae4194-4c1d-46be-8ab4-7b100a8cb239",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mean(): could not infer output dtype. Input dtype must be either a floating point or complex dtype. Got: Long",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#mean (Average)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m tensor\u001b[38;5;241m.\u001b[39mdtype\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mean(): could not infer output dtype. Input dtype must be either a floating point or complex dtype. Got: Long"
     ]
    }
   ],
   "source": [
    "#mean (Average)\n",
    "torch.mean(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b1c0f7d0-1d35-45d1-809c-c0e3b91eb3ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.dtype #int64 is Long!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "63ca2bb2-6bb7-49ed-9d59-5665be9c2c97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(48.7900, dtype=torch.float64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#our tensor's datatype is int64, but we need to pass float or complex!\n",
    "#for that we can change the datatype\n",
    "torch.mean(tensor.type(torch.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b5cbcc5f-8d1a-444c-8f4f-1797c7da3c2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(48.7900)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Note: torch.mean() function requires a tensor of float or complex datatype\n",
    "torch.mean(tensor,dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d23fff66-9f9d-45c9-a8cc-eec9b6ee4a47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(48.7900, dtype=torch.float64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.type(torch.float64).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1948e549-18cd-4c51-a41e-243d65c08033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4879)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor(4879)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find the sum\n",
    "torch.sum(tensor)\n",
    "\n",
    "#similar operation\n",
    "tensor.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc30ddf-85e6-4ab8-8ceb-7b1f7d6ede8f",
   "metadata": {},
   "source": [
    "## Finding the Positional Min and Max of Tensors\n",
    "\n",
    "argmin(), argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "74cf4c98-6e7c-42a0-b009-b7bcd2232d80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([23, 25, 99,  7, 31, 83, 81, 83, 43, 42, 73, 76, 99, 33, 43,  6, 97, 55,\n",
       "        47, 71, 58, 98, 51, 46, 83, 25, 17, 17, 99, 52, 93, 69, 42, 32, 72, 74,\n",
       "        83, 42, 81, 25, 34, 51, 42, 48,  4, 55, 12, 56, 82, 17, 83, 61, 15, 22,\n",
       "        47, 12, 96, 61, 80, 42,  3, 47, 99, 44, 52, 55, 19, 42, 89, 11, 24, 81,\n",
       "         3, 26, 82, 18, 98,  6, 10, 17, 62, 40, 11, 56, 39, 70, 45, 97, 75, 10,\n",
       "        89, 26, 18,  9, 37, 55,  9, 42, 11, 56])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ae681110-c193-4a67-bb54-a86396c84176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(60)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.argmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4aa00b73-f17e-428a-bd40-6f485d117649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor[60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "196095c0-6c9d-40a7-a0af-66e315bdbeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Argmin ---> Argmin will returns the index of minimum value in the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "09175742-914e-4722-91d1-6c6d77cc1266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d27813f1-38c8-4140-aab7-7a22d71b3827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5240d9cd-f1b3-4baa-8971-c6a86618e240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(99)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d10f31-cd3e-4edb-a4ab-f346ffbbf052",
   "metadata": {},
   "source": [
    "## Reshaping, Stacking, Squeezing, UnSqueezing tensors\n",
    "\n",
    "* Reshaping - reshapes an input tensor to a defined shape!\n",
    "\n",
    "* View - return a view of an input tensor of certain shape but keep the same memory as the orginal tensor.\n",
    "\n",
    "* Stacking - combine the multiple tensors - on top of each other (vstack - vertically stacking) or side by side (hstack - horizontal stacking)\n",
    "\n",
    "  -> concatenates a sequence of tensors along a new dimension.\n",
    "\n",
    "* Squeeze - removes all `1` dimensions from a tensor.\n",
    "\n",
    "* Unsqueeze - add a `1` dimension to a target tensor.\n",
    "\n",
    "* Permute -  Return a view of the input with dimensions permuted (swapped) in a certain way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4d782a5-e1a6-4b73-a8e7-46d19d2839da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]), torch.Size([9]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's create a tensor \n",
    "\n",
    "x = torch.arange(1.,10)\n",
    "\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e726d87-8ba1-449f-a1e1-e26eaad71aea",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[1, 7]' is invalid for input of size 9",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Add a extra dimension \u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#Note: keep in mind, our desired shape should compatible with orginal shape\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m x_reshaped \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m x_reshaped\n",
      "\u001b[1;31mRuntimeError\u001b[0m: shape '[1, 7]' is invalid for input of size 9"
     ]
    }
   ],
   "source": [
    "#Add a extra dimension \n",
    "#Note: keep in mind, our desired shape should compatible with orginal shape\n",
    "x_reshaped = x.reshape(1,7)\n",
    "x_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be7024e2-0e49-4eb5-be09-9c164a8d5fc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_reshaped = x.reshape(1,9)\n",
    "x_reshaped\n",
    "\n",
    "# [[1., 2., 3., 4., 5., 6., 7., 8., 9.]]\n",
    "# here we can see, we just added a single dimension  \n",
    "\n",
    "#reshape(1,9) -> 1 row and 9 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "badbb010-ef81-4770-aa39-e808a9248b9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [2.],\n",
       "        [3.],\n",
       "        [4.],\n",
       "        [5.],\n",
       "        [6.],\n",
       "        [7.],\n",
       "        [8.],\n",
       "        [9.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([9, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "## we are changing the shape to reshape (9,1) -> 9 rows and 1 column\n",
    "x_reshaped = x.reshape(9,1)\n",
    "x_reshaped\n",
    "\n",
    "x_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbc2a8a4-f9f6-4781-acec-9d5e5d38253d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([18])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(1,19)\n",
    "\n",
    "x \n",
    "\n",
    "x.shape\n",
    "\n",
    "#here we have single dimension tensor with 18 elements in it!\n",
    "#It's shape is 1 row, 18 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d825a6d-74ef-43e7-8ced-46980e7da917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
       "        [10, 11, 12, 13, 14, 15, 16, 17, 18]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 9])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#I want to reshape it into 2 rows 9 columns\n",
    "x_reshaped = x.reshape((2,9))\n",
    "\n",
    "x_reshaped\n",
    "\n",
    "x_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1f12238d-35c4-488e-b2b5-8b9a2e2beaff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([18])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Change the view!\n",
    "x_org = torch.arange(1,19)\n",
    "\n",
    "x_org\n",
    "\n",
    "x_org.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ff548130-4088-4d17-830f-e1e3937cef56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
       "        [10, 11, 12, 13, 14, 15, 16, 17, 18]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 9])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = x_org.view((2,9))\n",
    "\n",
    "z \n",
    "\n",
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e3dc8b9-807d-4fca-ad4f-82cf7f891e04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9eb7d88-bbaf-4ccc-9ecf-cd8d6e5551a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#View is similar to reshape \n",
    "# view shares the memory with orginal tensor \n",
    "# z is different view of orginal tensor x. \n",
    "#So z shares the same memory as what x does! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "61ad43a4-f90f-4e30-a6e1-0e584eff8c74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
       "        [10, 11, 12, 13, 14, 15, 16, 17, 18]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1000,    2,    3,    4,    5,    6,    7,    8,    9],\n",
       "        [  10,   11,   12,   13,   14,   15,   16,   17,   18]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's examplify this! \n",
    "# So, changing z, changes x. (because a view of a tensor shares the same memory as the original tensor!) \n",
    "#Bascially it's a shallow copy of orginal tensor! so if we change something it will reflect it int the original tensor\n",
    "#Remember it \n",
    "\n",
    "#example \n",
    "#let's just change the first element of z (view of x)\n",
    "z\n",
    "\n",
    "#reassigning 1 with 1000\n",
    "z[0,0] = 1000\n",
    "\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "835ceff3-e1b7-485c-844d-544161e8db47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1000,    2,    3,    4,    5,    6,    7,    8,    9],\n",
       "         [  10,   11,   12,   13,   14,   15,   16,   17,   18]]),\n",
       " tensor([1000,    2,    3,    4,    5,    6,    7,    8,    9,   10,   11,   12,\n",
       "           13,   14,   15,   16,   17,   18]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This re-assignment will reflect also on x (org tensor)\n",
    "z, x_org"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d494e1b1-167d-4f76-a069-f297525c7787",
   "metadata": {},
   "source": [
    "### Stacking \n",
    "\n",
    "stack some tensors on top of each other or side by side !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2fa4869c-7040-49dc-a222-e6092f59dc73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([5])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(1,6)\n",
    "\n",
    "x\n",
    "\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1393f370-8dc2-41a3-9171-a03cd94add77",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "stack(): argument 'tensors' (position 1) must be tuple of Tensors, not Tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m x_stacked \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: stack(): argument 'tensors' (position 1) must be tuple of Tensors, not Tensor"
     ]
    }
   ],
   "source": [
    "x_stacked = torch.stack(x,dim=0)\n",
    "\n",
    "#must be tuple of Tensors, not a Tensor \n",
    "#that means we need to provide List of Tensors!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "af55d31b-64c8-4362-81a3-e2e1a2f12b5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3, 4, 5],\n",
       "        [1, 2, 3, 4, 5]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_stacked = torch.stack([x,x],dim=0)\n",
    "\n",
    "#we stacked x twice in vertically\n",
    "x_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7a450e62-bfc7-4bd7-b990-d0fd96a94349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3, 4, 5],\n",
       "        [1, 2, 3, 4, 5],\n",
       "        [1, 2, 3, 4, 5],\n",
       "        [1, 2, 3, 4, 5],\n",
       "        [1, 2, 3, 4, 5]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_stacked = torch.stack([x,x,x,x,x],dim=0)\n",
    "\n",
    "#we stacked x twice in vertically\n",
    "#if we provide dim=0 that means it will stack in row. stacks in vertically way.\n",
    "x_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ddb76dac-ffb6-4f9b-b84f-859700adfd3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1],\n",
       "        [2, 2, 2, 2, 2],\n",
       "        [3, 3, 3, 3, 3],\n",
       "        [4, 4, 4, 4, 4],\n",
       "        [5, 5, 5, 5, 5]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#if we provide dim=1 that means it will stack in columns. stacks in horizontal way.\n",
    "x_stacked = torch.stack([x,x,x,x,x],dim=1)\n",
    "x_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e5e44496-01e2-41c3-8c5c-26583a3d4441",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We also have other function to perform stacking()\n",
    "# vstack() -> performs stacking vertically that means we can stack one tensor on top another\n",
    "# hstack() -> performs stacking horizontally that means we can stack one tensor beside another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "54bd7d49-4897-42ec-8d8f-2e9860c5c141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([5])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_org = torch.arange(1,6)\n",
    "\n",
    "x_org\n",
    "\n",
    "x_org.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "447dfe38-fb98-436f-8a99-08d9d3b2da80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3, 4, 5],\n",
       "        [1, 2, 3, 4, 5]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#torch.vstack() -> input: Tensors (list of tensors)\n",
    "#Stack tensors in sequence vertically (row wise).\n",
    "x_vstacked = torch.vstack([x_org,x_org])\n",
    "\n",
    "x_vstacked\n",
    "\n",
    "x_vstacked.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f71129d3-17e3-40e7-bdab-6fe7f8a74032",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected Tensor as element 0 in argument 0, but got list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#torch.hstack() -> input: Tensors (list of tensors)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m x_hstacked \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_org\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx_org\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m x_hstacked\n\u001b[0;32m      6\u001b[0m x_hstacked\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[1;31mTypeError\u001b[0m: expected Tensor as element 0 in argument 0, but got list"
     ]
    }
   ],
   "source": [
    "#torch.hstack() -> input: Tensors (list of tensors)\n",
    "#Stack tensors in sequence horizontally (column wise).\n",
    "x_hstacked = torch.hstack([x_org,x_org])\n",
    "\n",
    "x_hstacked\n",
    "\n",
    "x_hstacked.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba87f34-2f90-4c4c-9dc1-ad688e5d9708",
   "metadata": {},
   "source": [
    "## Squeeze \n",
    "\n",
    "torch.squeeze() -> removes all single dimensions from a target tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "48fe8a6e-40b8-4c7e-bbb9-da11d3774114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 9])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_org = torch.arange(1,10,dtype=torch.float64)\n",
    "\n",
    "x_org = x_org.reshape((1,9))\n",
    "\n",
    "x_org\n",
    "\n",
    "x_org.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a853abe0-af96-430a-acc0-679c040d266f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.], dtype=torch.float64)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([9])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_squeezed = x_org.squeeze()\n",
    "\n",
    "x_squeezed\n",
    "\n",
    "x_squeezed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "07337efa-911b-4f1f-b632-c299b6f862db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Squeeze will remove all single dimensions from target tensor\n",
    "#example: \n",
    "#x_org = tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]], dtype=torch.float64)\n",
    "#torch.Size([1, 9])\n",
    "#x_org size is [1,9] \n",
    "#After squeezing, it will remove single dimensions from x_org \n",
    "#so output size will be [9]\n",
    "\n",
    "#if x_org size is [1,1,9]\n",
    "# after squeezing, output size will be [9], two single 1 dimensions will be removed! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f1273742-a0d6-4066-be3f-0d9d088f8a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orginal tensor: tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0.]]])\n",
      "\n",
      "Orginal tensor's shape: torch.Size([1, 1, 9])\n",
      "\n",
      "Squeezed tensor: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "\n",
      "Squeezed tensor's shape: torch.Size([9])\n"
     ]
    }
   ],
   "source": [
    "x_org = torch.zeros((1,1,9))\n",
    "\n",
    "print(f'Orginal tensor: {x_org}')\n",
    "\n",
    "print(f\"\\nOrginal tensor's shape: {x_org.shape}\") \n",
    "\n",
    "#Remove extra dimensions from x_org\n",
    "x_squeezed = x_org.squeeze()\n",
    "\n",
    "print(f'\\nSqueezed tensor: {x_squeezed}')\n",
    "\n",
    "print(f\"\\nSqueezed tensor's shape: {x_squeezed.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0c4dfe-561e-4c49-ac98-361a49d5be92",
   "metadata": {},
   "source": [
    "## Unsqueeze\n",
    "\n",
    "unsqueeze() -> adds a single dimensions to a target tensor at a specific dim (dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c7661c82-e8e3-4fcd-b23d-28ad79acc308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([9])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_org = torch.zeros((9))\n",
    "\n",
    "x_org\n",
    "\n",
    "x_org.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8190a40f-2306-43bc-987e-89014670dbc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orginal tensor: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "\n",
      "Orginal tensor's shape : torch.Size([9])\n",
      "\n",
      "Unsqueezed tensor: tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "\n",
      "Unsqueezed tensor: torch.Size([1, 9])\n"
     ]
    }
   ],
   "source": [
    "#we can add single dimension to x_org (as many we want!)\n",
    "print(f\"Orginal tensor: {x_org}\")\n",
    "\n",
    "print(f\"\\nOrginal tensor's shape : {x_org.shape}\")\n",
    "\n",
    "#adding single dimension (dim=0) -> on row\n",
    "x_unsqueezed = x_org.unsqueeze(dim=0)\n",
    "\n",
    "print(f\"\\nUnsqueezed tensor: {x_unsqueezed}\")\n",
    "\n",
    "print(f\"\\nUnsqueezed tensor: {x_unsqueezed.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8becd28-01a5-4fd0-ae81-d1d75130eb1f",
   "metadata": {},
   "source": [
    "## Permute \n",
    "\n",
    "permute() -> rearranges the dimensions of a target tensor in a specific order. \n",
    "\n",
    "One of the common places, you will be using Permute is with Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c4fb65e5-1f86-4237-84e9-1a865b4a86f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 244, 244])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_org = torch.rand((244, 244, 3)) #[height, width, depth(color_channels)]\n",
    "\n",
    "##Permute the orginal tensor to rearrange the axis or (dim) order!\n",
    "\n",
    "x_permuted = x_org.permute((2,0,1)) #Shifts axis 0->1, 1->2, 2->0\n",
    "\n",
    "x_permuted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "21a606be-31b5-4774-8a4b-e876b4db2085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orginal shape: torch.Size([244, 244, 3])\n",
      "\n",
      "New Shape: torch.Size([3, 244, 244])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Orginal shape: {x_org.shape}\")\n",
    "\n",
    "print(f\"\\nNew Shape: {x_permuted.shape}\") #[color_channels, Height, Width]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0675593e-89e2-4d63-b8f1-0f9e2e60cbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Note: Permute() -> view the new arrangment of tensor shape\n",
    "# so it will use same memory of target tensor.\n",
    "# if we do reassignment on permuted tensor, changes will reflect on original tensor!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5050a86f-8b87-4b04-9e69-eb3df8496a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#re-assigned \n",
    "x_permuted[0,0,0] = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "67063b23-d1a6-46a5-8702-b547bc7313d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(999.), tensor(999.))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_org[0,0,0], x_permuted[0,0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86ffaba-1f2d-427c-9bd3-0a279b22b406",
   "metadata": {},
   "source": [
    "## Indexing (selecting data from tensors)\n",
    "\n",
    "Indexing with Pytorch is similar to indexing with Numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2aa0c216-f00c-4863-b894-12632d40febf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [4, 5, 6],\n",
       "         [7, 8, 9]]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a tensor \n",
    "# [9] elements -> [[[],[],[]]]\n",
    "x = torch.arange(1,10).reshape((1,3,3))\n",
    "\n",
    "x\n",
    "\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8114e4f2-85d1-42c3-8b76-dab6d7440346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [4, 5, 6],\n",
       "         [7, 8, 9]]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's Index on our new tensor \n",
    "x\n",
    "\n",
    "#x[0] -> this is gonna index first bracket! (dim=0)\n",
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "64f145a6-4032-4b7f-8814-cdb9e20d80a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets index on the middle bracket (dim=1)\n",
    "x[0][0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6f562acc-a1b5-4350-9b42-380ea1627b71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#similar operation\n",
    "x[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c6d4d946-d7cb-4747-9338-65228e885d5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's index on most inner bracket! (dim=2)\n",
    "x[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "abaa1bc1-4bd7-4b38-bd2c-2d5167d65d15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0][2][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7e4e07d4-418a-4acc-a5b1-f8440c10de5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#You can also use \":\" to select \"all\" of a target dimension \n",
    "x[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "66fb64b4-9a46-427f-a586-a1b649236289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 5, 8]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get all values of 0th and 1st dimensions but only index 1 of 2nd dimension \n",
    "#x[depth, rows, column]\n",
    "x[:,:,1] #1st column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "07b95f2b-63e5-4a35-82ee-77cd4cb26530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get all values of 0th dimension but only the 1 index value of 1st and 2nd dimension \n",
    "x[:, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1b5da912-6555-4ec3-a6fe-caae356cf228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "47ab421e-dba4-4656-9044-f8e816ca542a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Index on x to return 9 \n",
    "x[0][2][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "688ba707-3cbd-4ce4-8b7a-288415487146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 6, 9])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Index on x to return 3,6,9\n",
    "x[0,:,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421ffb5e-24f4-4f34-9aa1-dcdbbb834fe3",
   "metadata": {},
   "source": [
    "## Pytorch and Numpy\n",
    "\n",
    "Numpy is a popular scientific python numerical computing library. \n",
    "\n",
    "And because of this, PyTorch has functionality to interact with it.  \n",
    "\n",
    "* Intially Data is in Numpy, want in PyTorch Tensor -> 'torch.from_numpy(ndarray)'\n",
    "\n",
    "* PyTorch Tensor to Numpy array -> 'torch.tensor.numpy()' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "988688cd-30f9-4f19-8c71-8c4c1422749f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2., 3., 4., 5., 6., 7.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Numpy array to tensor \n",
    "import torch \n",
    "import numpy as np\n",
    "\n",
    "array = np.arange(1.0,8.0)\n",
    "\n",
    "array\n",
    "\n",
    "type(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82562b11-5eab-46e7-9764-f2e62421462e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#converting it into pytorch tensor\n",
    "tensor = torch.from_numpy(array)\n",
    "\n",
    "tensor\n",
    "\n",
    "type(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84893baa-72da-41ca-b8d2-c08957a05e2c",
   "metadata": {},
   "source": [
    "#### Note: Numpy array's default datatype is 'float64' and \n",
    "#### PyTorch tensor's default datatype is 'float32'... \n",
    "#### when you convert from numpy array to tensor, it will make tensor with float64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44ffec6f-428a-4232-bc95-ffac7d4cfdb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#default datatype\n",
    "torch.arange(1.0,8.0).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf0ee192-b2f9-41fa-ab01-77cd4108ddc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warning: when converting from numpy -> pytorch,\n",
    "# pytorch reflects numpy's default datatype of float64. unless specified otherwise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6118f61d-2597-48f3-be5d-2e803c2f1e04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2., 3., 4., 5., 6., 7.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([2., 3., 4., 5., 6., 7., 8.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Changing the value of numpy array, does that change will impact on tensor!\n",
    "array\n",
    "\n",
    "array = array + 1 \n",
    "\n",
    "array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fd221220-d821-44b3-b315-ec40d1986bf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a068d098-d1f2-47b0-bb49-110e4273dc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: you can see tensor has no impact when numpy array was changed! \n",
    "# so we can say that tensor was created in another memory location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "55b251d6-76e1-433e-b7f8-3a593d654a84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tensor to numpy array \n",
    "tensor = torch.ones(7)\n",
    "\n",
    "tensor\n",
    "\n",
    "tensor.dtype\n",
    "\n",
    "type(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1ff172d0-4b18-43d4-b2fe-913f89459786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1.], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_array = tensor.numpy()\n",
    "\n",
    "numpy_array\n",
    "\n",
    "numpy_array.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dc701af6-f425-4e6e-87d7-7ece5e72c85c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 2., 2., 2., 2., 2., 2.])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Change the tensor, what happens to 'numpy_array'\n",
    "tensor = tensor + 1 \n",
    "\n",
    "tensor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "240086b0-7093-4b0a-bdc0-a5afcb9e6ea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1.], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "677c87a2-7de7-4790-9e1a-cc7977ff60a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#That means they don't share memory!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03f5f89-4f17-40e6-a435-1fe477bae974",
   "metadata": {},
   "source": [
    "## Reproducbility (Trying to take random out of random)\n",
    "\n",
    "In short how neural network learns: \n",
    "\n",
    "'start with random numbers' -> tensor operation -> update random numbers to try and make them better representation of data -> again -> again -> again ....\n",
    "\n",
    "To reduce the randomness in neural networks and PyTorch comes a concept of **random seed** \n",
    "\n",
    "Essentially what the random seed does is 'flavour' the randomness!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "940097a5-bf42-49fc-9d3d-b156dc60b643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8284, 0.1811, 0.2566],\n",
       "        [0.3302, 0.2041, 0.9313],\n",
       "        [0.3197, 0.7942, 0.5014]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d24411ba-0929-45a4-8e9b-0c5eba333e04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1799, 0.6213, 0.6339],\n",
       "        [0.7754, 0.5735, 0.8836],\n",
       "        [0.0504, 0.9115, 0.7943]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef9b5b8-b8c6-4d94-9513-00796da5bd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Everytime we get random numbers!  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "561bd0e3-e973-454d-bbcd-ad58ea16313d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#psuedo randomness -> generated randomness!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "609179c8-2f15-4c8a-98ef-d881ba9cabbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3741, 0.8869, 0.8357, 0.7385],\n",
       "        [0.3695, 0.9953, 0.8811, 0.9889],\n",
       "        [0.2801, 0.8135, 0.5623, 0.2242]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.5025, 0.1573, 0.9214, 0.4304],\n",
       "        [0.6659, 0.9596, 0.5949, 0.6834],\n",
       "        [0.0392, 0.3951, 0.9399, 0.8519]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[False, False, False, False],\n",
      "        [False, False, False, False],\n",
      "        [False, False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "#create two random tensors\n",
    "random_tensor_A = torch.rand((3,4))\n",
    "random_tensor_B = torch.rand((3,4))\n",
    "\n",
    "\n",
    "random_tensor_A\n",
    "\n",
    "random_tensor_B\n",
    "\n",
    "print(random_tensor_A == random_tensor_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "51f550c7-b205-41a6-9261-6c3231c4f79a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x207c030fb50>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x207c030fb50>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
       "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
       "        [0.9408, 0.1332, 0.9346, 0.5936]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
       "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
       "        [0.9408, 0.1332, 0.9346, 0.5936]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True],\n",
       "        [True, True, True, True],\n",
       "        [True, True, True, True]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's make some random but reproducible tensors\n",
    "\n",
    "#set the random seed!\n",
    "RANDOM_SEED = 42  \n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "\n",
    "#create some random tensors \n",
    "random_tensor_A = torch.rand((3,4))\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "random_tensor_B = torch.rand((3,4))\n",
    "\n",
    "random_tensor_A\n",
    "\n",
    "random_tensor_B\n",
    "\n",
    "random_tensor_A == random_tensor_B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c66be2-06b6-4ecd-bb46-c64b4879ceec",
   "metadata": {},
   "source": [
    "### Extra Resources: \n",
    "* https://pytorch.org/docs/stable/notes/randomness.html\n",
    "* https://en.wikipedia.org/wiki/Random_seed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fa887d-ab18-4bd0-9e7c-043ad804598f",
   "metadata": {},
   "source": [
    "## Running tensors and PyTorch objects on the GPU's (and making faster computations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb11275-da97-48ec-aed9-77eb64cf44d3",
   "metadata": {},
   "source": [
    "GPUs -> faster computation on numbers, thanks to CUDA + NVIDIA hardware + PyTorch working behind the scenes to make everything hunky dory (good). \n",
    "\n",
    "hunky dory -> fine, going well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1132a2cf-4125-4363-bdd0-18cddaed45c6",
   "metadata": {},
   "source": [
    "### 1. Getting a GPU \n",
    "\n",
    "1. **Easiest** - Use Google Colab for a free GPU (options to upgrade as well)\n",
    "2. Use your own GPU - takes a little bit of setup and requires the investment!\n",
    "   \n",
    "    See this blog post to see which GPU hardware to get...\n",
    "    Best GPU for Deep learning: https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/\n",
    "\n",
    "3. Use Cloud Computing - GCP, AWS, Azure, ect....\n",
    "    These services allow you to rent computers on the cloud and access them!\n",
    "\n",
    "\n",
    "* For 2, 3 Options. Pytorch + GPU drivers (CUDA) takes a little bit of setting up, to do this, refer the Pytorch setup documentation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6f67075d-aac7-4144-a3ee-52336bf19786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Nov  5 12:34:50 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 529.08       Driver Version: 529.08       CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA T1200 La... WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   56C    P8     3W /  35W |     88MiB /  4096MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     29164    C+G   ...ser\\Application\\brave.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa018f1-158d-4722-91b1-9862bd405923",
   "metadata": {},
   "source": [
    "## 2. Check for GPU access with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32a1a146-3424-4750-b114-f779c59b290b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for GPU access with PyTorch.\n",
    "import torch\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f01d6b2b-a709-4391-80f1-2429f82e8dfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Setup Device Agnostic Code\n",
    "device = \"cuda\" if torch.cuda.is_available() else  \"cpu\"\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6938b0e7-3765-487b-844d-f5705274ad81",
   "metadata": {},
   "source": [
    "set device to CUDA, if there is a gpu available, or else it will set it to cpu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bf585d2-e4c6-4331-824f-9055b28d37e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Count no of devices (GPUs)   \n",
    "torch.cuda.device_count()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c56f255-be07-4f4b-b733-e6d480fd71fa",
   "metadata": {},
   "source": [
    "extra resources about device agnostic code - https://pytorch.org/docs/stable/notes/cuda.html#device-agnostic-code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4522423-70aa-4b6d-b419-84af9bf27708",
   "metadata": {},
   "source": [
    "## 3. How actually we can use the GPU\n",
    "### Puttting tensors and models on GPU. \n",
    "\n",
    "The reason why we want our tensors/models on the GPU is because using a GPU results in faster computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15d8df6d-b754-433b-964b-d54c34f884bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 3]), device(type='cpu'))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a tensor (default on the CPU)\n",
    "tensor = torch.tensor([1,2,3])\n",
    "\n",
    "tensor, tensor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b305072d-6a19-47a2-b014-7a40aa18398b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Move tensor to GPU (if available)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "device\n",
    "\n",
    "#tensor which is on cpu\n",
    "tensor, tensor.device\n",
    "\n",
    "tensor_on_gpu = tensor.to(device)\n",
    "\n",
    "tensor_on_gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5e3032-7b47-4004-8935-ef24a1f092df",
   "metadata": {},
   "source": [
    "**cuda:0**, 0 is the index of the GPU that we are using!. \n",
    "\n",
    "we have 1 GPU, it's index is 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddd4a3d-61cb-4742-af46-9c419a295d29",
   "metadata": {},
   "source": [
    "### 4. Moving Tensor back to the CPU\n",
    "\n",
    "because, Numpy only works with CPU. so you need to get back from GPU to CPU to perform such operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5452cc95-dc73-46d0-bf7a-e234d47941b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# If the tensor is on GPU, can't transform it to Numpy. \u001b[39;00m\n\u001b[0;32m      2\u001b[0m tensor_on_gpu\n\u001b[1;32m----> 4\u001b[0m \u001b[43mtensor_on_gpu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "# If the tensor is on GPU, can't transform it to Numpy. \n",
    "tensor_on_gpu\n",
    "\n",
    "tensor_on_gpu.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35c72b41-c8c6-474a-84be-b1e4f78b9147",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We will get device errors!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b52bfbbe-fbac-4eff-b385-e33836e2e7d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], device='cuda:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To fix the GPU tensor with Numpy issue. we can first set it to the CPU.\n",
    "tensor_on_gpu\n",
    "\n",
    "tensor_back_on_cpu = tensor_on_gpu.cpu()\n",
    "\n",
    "tensor_back_on_cpu\n",
    "\n",
    "tensor_back_on_cpu.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "679b3cb9-a05a-43b1-811f-29884d763f14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now it is working! \n",
    "tensor_back_on_cpu.numpy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
